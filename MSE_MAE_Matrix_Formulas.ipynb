{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/n Σ(actual y - predicted y)2  --> square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alt + 228 = Σ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/n Σ|(actual y - predicted y)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE Root Mean Suqare Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE = √MSE = √1/n Σ(actual y - predicted y)2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alt + 251 = √"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huber Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Huber Loss or Smooth Mean Absolute Error is a loss \n",
    "function that takes the advantageous characteristics of the Mean Absolute Error \n",
    "and Mean Squared Error loss functions and combines them into a single loss function.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In machine learning, a confusion matrix is a table that visually summarizes the performance of a \n",
    "classification model by comparing its predictions against the actual results, \n",
    "showing the counts of true positives, true negatives, false positives, and false negatives'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP - Model-positive, actual-positive\n",
    "# TN - Model-negative, actual-negative\n",
    "# FP - Model-positive, actual-negative\n",
    "# FN - Model-negative, actual-positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' In machine learning, accuracy measures the model's overall \n",
    "correctness by calculating the ratio of correct predictions \n",
    "(both true positives and true negatives) to the total number of predictions. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy = (TP + TN)/(TP+TN+FP+FN)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In machine learning, precision measures the accuracy of \n",
    "positive predictions, specifically the proportion of true positive predictions\n",
    "among all positive predictions made by the model, aiming to minimize false positives. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision = TP/(TP+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In machine learning, recall, also known as sensitivity or true positive rate, \n",
    "measures a model's ability to identify all actual positive cases, \n",
    "focusing on minimizing false negatives. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall = TP/(TP + FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The F1 score is a machine learning metric that evaluates a model's accuracy by \n",
    "combining precision and recall into a single score, \n",
    "offering a balanced view of performance, especially useful in imbalanced datasets'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score =  (2 * P * R)/(P + R)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
